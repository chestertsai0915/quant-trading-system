import logging
import pandas as pd
import time
from data_sources.registry import get_all_fetchers
from data_loader import DataLoader

class DataManager:
    def __init__(self, client, db, symbol, interval):
        self.client = client
        self.db = db
        self.symbol = symbol
        self.interval = interval
        self.loader = DataLoader(self.client, self.db)
        self.fetchers = get_all_fetchers()
        self.last_processed_time = 0
        
        logging.info(f"è¼‰å…¥å¤–éƒ¨æ•¸æ“šæº: {list(self.fetchers.keys())}")

    def get_history_klines(self, limit=1500):
        """ ç²å–æ­·å² K ç·š (ç†±æ©Ÿç”¨) """
        return self.loader.get_binance_klines(self.symbol, self.interval, limit=limit)

    def check_new_candle(self):
        """ 
        åµæ¸¬æ˜¯å¦æœ‰æ–°æ”¶ç›¤çš„ K ç·š 
        Return: (bool, int, dataframe) -> (æ˜¯å¦æ–°Kç·š, æ”¶ç›¤æ™‚é–“, å‰›æ”¶ç›¤çš„Kç·šè³‡æ–™)
        """
        # æŠ“å–æœ€æ–°çš„ 2 æ ¹
        raw_df = self.loader.get_binance_klines(self.symbol, self.interval, limit=2)
        
        if raw_df.empty:
            return False, 0, None

        # å–å¾—å€’æ•¸ç¬¬äºŒæ ¹ (å‰›æ”¶ç›¤çš„)
        latest_closed_kline = raw_df.iloc[-2]
        closed_time = int(latest_closed_kline['open_time'])

        if closed_time > self.last_processed_time:
            # é€™æ˜¯æ–° K ç·š
            return True, closed_time, raw_df.iloc[:-1] # å›å‚³æ’é™¤æœªæ”¶ç›¤çš„æ•¸æ“š
        
        return False, 0, None

    def update_etl_process(self, closed_time, df_to_save):
        """ åŸ·è¡Œæ¨™æº– ETL æµç¨‹ """
        logging.info(f"[ETL] è™•ç†æ–° K ç·š: {pd.to_datetime(closed_time, unit='ms')}")
        
        # 1. å­˜å…¥ Market Data
        self.db.save_market_data(self.symbol, self.interval, df_to_save)
        
        # 2. æ›´æ–°å¤–éƒ¨æ•¸æ“š
        self._update_external_data()
        
        # 3. è®€å›çµ¦ç­–ç•¥ç”¨çš„æ•¸æ“š
        #strategy_df = self.db.load_market_data(self.symbol, self.interval, limit=200)
        strategy_df = self.get_strategy_data(limit=200)
        # æ›´æ–°å…§éƒ¨ç‹€æ…‹
        self.last_processed_time = closed_time
        
        return strategy_df

    def _update_external_data(self):
        """ æŠ“å–å¤–éƒ¨æ•¸æ“šä¸¦å­˜æª” """
        for name, fetcher in self.fetchers.items():
            try:
                df = fetcher.fetch_data()
                if df.empty: continue

                if name == 'us_stock_qqq':
                    self.db.save_market_data(symbol='QQQ', interval='1d', df=df)
                else:
                    self.db.save_generic_external_data(df)
            except Exception as e:
                logging.error(f"å¤–éƒ¨æ•¸æ“šæ›´æ–°å¤±æ•— [{name}]: {e}")

    def get_strategy_data(self, limit=200):
        """
        é€™æ˜¯å¯¦ç›¤èˆ‡å›æ¸¬å…±ç”¨çš„æ•¸æ“šæº–å‚™é‚è¼¯
        åŠŸèƒ½ï¼š
        1. è®€å– K ç·š (ä¸»æ™‚é–“è»¸)
        2. è®€å–å„ç¨®å¤–éƒ¨æ•¸æ“š (ä¸åŒæ™‚é–“è»¸)
        3. ç”¨ merge_asof é€²è¡Œå°é½Š (ç­‰åŒæ–¼ ffill)
        """
        
        # 1. è®€å–ä¸» K ç·š (ä½ çš„ Time Anchor)
        df = self.db.load_market_data(self.symbol, self.interval, limit=limit)
        if df.empty: return pd.DataFrame()
        
        # ç¢ºä¿æŒ‰æ™‚é–“æ’åº (merge_asof çš„è¦æ±‚)
        df = df.sort_values('open_time')

        # 2. æº–å‚™å¤–éƒ¨æ•¸æ“šåˆ—è¡¨
        # é€™è£¡åˆ—å‡ºä½ æƒ³è¦åˆä½µçš„æŒ‡æ¨™
        external_metrics = ['fear_greed', 'funding_rate', 'fed_assets', 'google_trends']
        
        # å–å¾— K ç·šçš„æœ€æ—©æ™‚é–“ï¼Œæˆ‘å€‘åªéœ€è¦æŠ“é€™ä¹‹å¾Œçš„å¤–éƒ¨æ•¸æ“š (ç¨å¾®å¤šæŠ“ä¸€é»ç·©è¡)
        start_time = int(df['open_time'].min()) - 86400000 # å¤šæŠ“ä¸€å¤©ç·©è¡

        for metric in external_metrics:
            # A. è®€å–è©²æŒ‡æ¨™çš„æ•¸æ“š
            # æ³¨æ„ï¼šé€™è£¡å¯èƒ½å›å‚³ç©º DataFrame (å¦‚æœå‰›å¥½é€™æ®µæ™‚é–“æ²’æ•¸æ“š)
            ext_df = self.db.load_external_data(
                symbol='GLOBAL' if metric != 'funding_rate' else self.symbol, 
                metric=metric, 
                start_time=start_time
            )
            
            if not ext_df.empty:
                ext_df = ext_df.sort_values('open_time')
                
                # B. ğŸ”¥ æ ¸å¿ƒå‹•ä½œï¼šmerge_asof (å‘å¾ŒæŸ¥æ‰¾)
                # é€™å°±æ˜¯åœ¨åš "Forward Fill"
                # å®ƒæœƒå¹« df çš„æ¯ä¸€è¡Œï¼Œæ‰¾åˆ° ext_df è£¡ open_time <= df.open_time çš„æœ€æ–°ä¸€ç­†
                df = pd.merge_asof(
                    df,
                    ext_df[['open_time', 'value']], # åªå–éœ€è¦çš„æ¬„ä½
                    on='open_time',
                    direction='backward', # å‘å¾Œçœ‹ = æ‰¾éå»æœ€è¿‘çš„ = Last Known Value
                    suffixes=('', f'_{metric}')
                )
                
                # C. æ¬„ä½æ•´ç†
                # merge_asof æœƒç”¢ç”Ÿ 'value' æˆ– 'value_fear_greed' é€™æ¨£çš„æ¬„ä½
                # æˆ‘å€‘æŠŠå®ƒçµ±ä¸€æ”¹æˆ metric åç¨±
                target_col = f'value_{metric}' if f'value_{metric}' in df.columns else 'value'
                if target_col in df.columns:
                    df.rename(columns={target_col: metric}, inplace=True)
                
                # D. è£œæ¼ (Fail-safe)
                # å¦‚æœ K ç·šæœ€å‰é¢å¹¾ç­†å‰›å¥½æ²’æœ‰å°æ‡‰çš„å¤–éƒ¨æ•¸æ“š (å› ç‚º start_time åˆ‡å¤ªæº–)ï¼Œæœƒè®Šæˆ NaN
                # é€™æ™‚å€™ç”¨ ffill è£œé½Šï¼Œç¢ºä¿ä¸æœƒæœ‰ç©ºå€¼
                df[metric] = df[metric].ffill().fillna(0) # çœŸçš„éƒ½æ²’æœ‰å°±å¡« 0
            
            else:
                # å¦‚æœè³‡æ–™åº«å®Œå…¨æ²’æœ‰é€™å€‹æŒ‡æ¨™çš„æ•¸æ“šï¼Œå¡« 0 é¿å…å ±éŒ¯
                df[metric] = 0

        return df